{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmacl\\Anaconda3\\lib\\site-packages\\mpl_finance.py:22: DeprecationWarning: \n",
      "\n",
      "  =================================================================\n",
      "\n",
      "   WARNING: `mpl_finance` is deprecated:\n",
      "\n",
      "    Please use `mplfinance` instead (no hyphen, no underscore).\n",
      "\n",
      "    To install: `pip install --upgrade mplfinance` \n",
      "\n",
      "   For more information, see: https://pypi.org/project/mplfinance/\n",
      "\n",
      "  =================================================================\n",
      "\n",
      "  category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading : \n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from network import *\n",
    "from data import *\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from mpl_finance import candlestick_ohlc\n",
    "import json\n",
    "\n",
    "print(\"Loading : \")\n",
    "\n",
    "train_data = load_data(['2018', '2019'], ['BTCUSDT', 'ETHUSDT','LTCUSDT'], '5m')\n",
    "test_data = load_data(['2020'], ['BTCUSDT', 'ETHUSDT', 'LTCUSDT'], '5m')\n",
    "#train_data = load_data(['2020'], ['BTCUSDT', 'ETHUSDT', 'LTCUSDT'], '5m')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with 6421567 parameters\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'continuous_columns' : ['Open', 'High', 'Low', 'Close', 'Volume'],\n",
    "    'discrete_columns' : ['Hour'],#, 'Day', 'Month']\n",
    "    'target_columns' : ['Close'],\n",
    "    'n_var_past_continuous' : 5,\n",
    "    'n_var_future_continuous' : 0,\n",
    "    'n_var_past_discrete' : [24],#, 31, 12]\n",
    "    'n_var_future_discrete' : [24],#, 31, 12]\n",
    "    'n_var_static_discrete' : [5],\n",
    "\n",
    "    'batch_size' : 20,\n",
    "    'test_batch_size' : 20,\n",
    "    'n_tests' : 25,\n",
    "    'dim_model' : 140,\n",
    "    'n_lstm_layers' : 3,\n",
    "    'n_attention_layers' : 8,\n",
    "    'n_heads' : 8,\n",
    "    'dropout_r' : 0.05,\n",
    "\n",
    "    'quantiles' : [0.1, 0.5, 0.9],\n",
    "    \n",
    "    'past_seq_len' : 120,\n",
    "    'future_seq_len' : 24\n",
    "}\n",
    "\n",
    "load_model = True\n",
    "dir = \"D/\"\n",
    "#path = dir+\"model_119200.pt\"\n",
    "path = dir +\"model_198800.pt\"\n",
    "with open(dir + 'params.json', 'w') as fp:\n",
    "    json.dump(params, fp)\n",
    "    \n",
    "    \n",
    "t = TFN(params).cuda()\n",
    "optimizer = torch.optim.Adam(t.parameters(), lr=0.0001)\n",
    "\n",
    "#try to load from checkpoint\n",
    "if load_model:\n",
    "    checkpoint = torch.load(path)\n",
    "    t = checkpoint['model_state']\n",
    "    #t.load_state_dict(checkpoint['model_state'].state_dict())\n",
    "    optimizer = checkpoint['optimizer_state']\n",
    "    losses = checkpoint['losses']\n",
    "    test_losses = checkpoint['test_losses']\n",
    "    print(\"Loaded model with {} parameters\".format(get_n_params(t)))\n",
    "else:    \n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    print(\"Initialised model with {} parameters\".format(get_n_params(t)))\n",
    "\n",
    "indexer = Indexer(1, train_data[0].shape[0] - (params['past_seq_len'] + params['future_seq_len'] + 1)\n",
    "                  , params['batch_size'])\n",
    "\n",
    "train_data_gens = []\n",
    "for d in train_data:\n",
    "    train_data_gens.append(get_batches(d, params['past_seq_len'], \n",
    "                params['future_seq_len'], params['continuous_columns'], params['discrete_columns'], \n",
    "                params['target_columns'], batch_size = params['batch_size'], indexer = indexer))\n",
    "    \n",
    "test_indexer = Indexer(1, test_data[0].shape[0] - (params['past_seq_len'] + params['future_seq_len'] + 1)\n",
    "                       , params['test_batch_size'])\n",
    "\n",
    "test_data_gens = []\n",
    "for idx, d in enumerate(test_data):\n",
    "    test_data_gens.append(get_batches(d, params['past_seq_len'], \n",
    "                params['future_seq_len'], params['continuous_columns'], params['discrete_columns'], \n",
    "                params['target_columns'], batch_size = params['test_batch_size'],\n",
    "                                      indexer = test_indexer, norm = train_data[idx]))\n",
    "    \n",
    "quantiles = torch.tensor(params['quantiles']).float().type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(411)\n",
    "ax1 = fig.add_subplot(412)\n",
    "ax2 = fig.add_subplot(413)\n",
    "ax3 = fig.add_subplot(414)\n",
    "plt.ion()\n",
    "\n",
    "fig.canvas.draw()\n",
    "fig.show()\n",
    "\n",
    "steps = 200000\n",
    "for e in range(steps):\n",
    "    #run model against test set every 50 batches\n",
    "    if(len(losses) % 50 == 0 and len(losses) != 0 ):\n",
    "        t.eval()\n",
    "        m_test_losses = []\n",
    "        for i in range(params['n_tests']):\n",
    "            test_loss,_ , _, _ = forward_pass(t, test_data_gens, params['test_batch_size'], quantiles, test_indexer)\n",
    "            m_test_losses.append(test_loss.cpu().detach().numpy())\n",
    "            del test_loss\n",
    "            del _\n",
    "        \n",
    "        test_losses.append(np.log10(np.array(m_test_losses).mean(axis = 0)))\n",
    "        t.train()\n",
    "        \n",
    "    #save model every 400 batches\n",
    "    if(len(losses) % 400 == 0 and len(losses) != 0):\n",
    "        torch.save({'model_state' : t,\n",
    "                    'optimizer_state': optimizer,\n",
    "                   'losses' : losses, 'test_losses' : test_losses} , dir + \"model_{}.pt\".format(len(losses)))\n",
    "    \n",
    "    #forward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss, net_out, vs_weights, given_data = forward_pass(t,  train_data_gens , params['batch_size'], quantiles, indexer)\n",
    "    \n",
    "    net_out = net_out.cpu().detach()[0]#[0]\n",
    "    #backwards pass\n",
    "    losses.append(np.log10(loss.cpu().detach().numpy()))\n",
    "    torch.mean(loss).backward()\n",
    "    optimizer.step()\n",
    "     \n",
    "    if(e % 50 == 0):\n",
    "        #loss graphs\n",
    "        fig.tight_layout(pad = 0.1)\n",
    "        ax.clear()\n",
    "        ax.title.set_text(\"Training loss\")\n",
    "        ax.plot(losses)\n",
    "\n",
    "        ax1.clear()\n",
    "        ax1.title.set_text(\"Test loss\")\n",
    "        ax1.plot(test_losses) \n",
    "        \n",
    "        #compare network out put and data\n",
    "        ax2.clear()\n",
    "        ax2.title.set_text(\"Network output comparison\")\n",
    "        c = given_data[0][0].cpu()\n",
    "        a = torch.arange(-params['past_seq_len'], 0).unsqueeze(-1).unsqueeze(-1).float()\n",
    "        c = torch.cat((a,c), dim = 1)\n",
    "        candlestick_ohlc(ax2, c.squeeze(), colorup = \"green\", colordown = \"red\")\n",
    "\n",
    "        ax2.plot(net_out[:,0], color = \"red\")\n",
    "        ax2.plot(net_out[:,1], color = \"blue\")\n",
    "        ax2.plot(net_out[:,2], color = \"red\")\n",
    "        ax2.plot(given_data[3].cpu().detach().numpy()[0], label = \"target\", color = \"orange\")\n",
    "\n",
    "        #visualise variable selection weights\n",
    "        vs_weights = torch.mean(torch.mean(vs_weights, dim = 0), dim = 0).squeeze()\n",
    "        vs_weights = vs_weights.cpu().detach().numpy()\n",
    "        ax3.clear()\n",
    "        ax3.title.set_text(\"Variable Selection Weights\")\n",
    "        plt.xticks(rotation=-30)\n",
    "        x = params['continuous_columns'] + params['discrete_columns']\n",
    "        ax3.bar(x = x, height = vs_weights)\n",
    "        fig.canvas.draw()\n",
    "    \n",
    "    del loss\n",
    "    del net_out\n",
    "    del vs_weights\n",
    "    del given_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Draw test cases\n",
    "fig = plt.figure()\n",
    "axes = []\n",
    "batch_size_ = 4\n",
    "\n",
    "for i in range(batch_size_):\n",
    "    axes.append(fig.add_subplot(511 + i))\n",
    "\n",
    "\n",
    "loss, net_out, vs_weights, given_data = forward_pass(t, test_data_gens, params['test_batch_size'], quantiles)\n",
    "net_out = net_out.cpu().detach()\n",
    "t.eval()\n",
    "for idx, a in enumerate(axes):\n",
    "    a.clear()\n",
    "    \n",
    "    c = given_data[0][idx].cpu()\n",
    "    \n",
    "    past_seq_len = params['past_seq_len']\n",
    "    b = torch.arange(-params['past_seq_len'], 0).unsqueeze(-1).unsqueeze(-1).float()\n",
    "    c = torch.cat((b,c), dim = 1)#[250:]\n",
    "    #print(c.shape)\n",
    "    candlestick_ohlc(a, c.squeeze(), colorup = \"green\", colordown = \"red\")\n",
    "    \n",
    "    a.plot(net_out[idx][:,0], color = \"red\")\n",
    "    a.plot(net_out[idx][:,1], color = \"blue\")\n",
    "    a.plot(net_out[idx][:,2], color = \"red\")\n",
    "    a.plot(given_data[3].cpu().detach().numpy()[idx], label = \"target\", color = \"orange\")\n",
    "\n",
    "t.train()    \n",
    "plt.ion()\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "\n",
    "del loss\n",
    "\n",
    "del net_out\n",
    "del vs_weights\n",
    "\n",
    "del given_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(losses ).argmin() #* 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_losses)[:,0].min() #* 50#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del loss\n",
    "del net_out\n",
    "del vs_weights\n",
    "\n",
    "del given_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
